{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./datasets/v0_eigens.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_eigens.shape = (45728, 896)\n",
      "train_labels.shape = (45728, 28)\n",
      "valid_eigens.shape = (11431, 896)\n",
      "valid_labels.shape = (11431, 28)\n"
     ]
    }
   ],
   "source": [
    "# NOTE: load the data from the npz\n",
    "dataset = np.load('./datasets/v0_eigens.npz')\n",
    "\n",
    "# NOTE: calculate the size of training set and validation set\n",
    "#       all pre-processed features are inside 'train_eigens'\n",
    "train_data_size = dataset['train_eigens'].shape[0]\n",
    "valid_data_size = train_data_size // 5\n",
    "train_data_size = train_data_size - valid_data_size\n",
    "\n",
    "# NOTE: split dataset\n",
    "train_data = dataset['train_eigens'][:train_data_size]\n",
    "valid_data = dataset['train_eigens'][train_data_size:]\n",
    "\n",
    "# NOTE: a 896d feature vector for each user, the 28d vector in the end are\n",
    "#       labels\n",
    "#       896 = 32 (weeks) x 7 (days a week) x 4 (segments a day)\n",
    "train_eigens = train_data[:, :-28].reshape(-1, 896)\n",
    "train_labels = train_data[:, -28:]\n",
    "\n",
    "valid_eigens = valid_data[:, :-28].reshape(-1, 896)\n",
    "valid_labels = valid_data[:, -28:]\n",
    "\n",
    "# NOTE: read features of test set\n",
    "test_eigens = dataset['issue_eigens'][:, :-28].reshape(-1, 896)\n",
    "\n",
    "# NOTE: check the shape of the prepared dataset\n",
    "print('train_eigens.shape = {}'.format(train_eigens.shape))\n",
    "print('train_labels.shape = {}'.format(train_labels.shape))\n",
    "print('valid_eigens.shape = {}'.format(valid_eigens.shape))\n",
    "print('valid_labels.shape = {}'.format(valid_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (45728, 224, 4)\n",
      "y_train.shape = (45728, 7, 4)\n",
      "x_valid.shape = (11431, 224, 4)\n",
      "y_valid.shape = (11431, 7, 4)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid, y_train, y_valid = [], [], [], []\n",
    "\n",
    "for i in range(len(train_eigens)):\n",
    "    x_train.append(train_eigens[i].reshape((-1, 4)))\n",
    "    y_train.append(train_labels[i].reshape((-1, 4)))\n",
    "    \n",
    "    if i < len(valid_eigens):\n",
    "        x_valid.append(valid_eigens[i].reshape((-1, 4)))\n",
    "        y_valid.append(valid_labels[i].reshape((-1, 4)))\n",
    "        \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_valid = np.array(x_valid)\n",
    "y_valid = np.array(y_valid)\n",
    "        \n",
    "print('x_train.shape = {}'.format(x_train.shape))\n",
    "print('y_train.shape = {}'.format(y_train.shape))\n",
    "print('x_valid.shape = {}'.format(x_valid.shape))\n",
    "print('y_valid.shape = {}'.format(y_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "learning_rate = 0.001\n",
    "train_iters = 100000\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input set up\n",
    "n_inputs = 4 # segments a day\n",
    "n_steps = 224 # day\n",
    "n_hidden_unis = 128 # neurons in a hidden layer\n",
    "n_days = 7\n",
    "n_segments = 4\n",
    "\n",
    "# tensorflow graph inputs\n",
    "x = tf.placeholder(tf.int32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None, n_days, n_segments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight and biases\n",
    "weights = {\n",
    "    'in': tf.Variable(tf.random_normal([n_inputs, n_hidden_unis])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_unis, n_days]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'in': tf.Variable(tf.constant(0.1, shape = [n_hidden_unis, ])),\n",
    "    'out': tf.Variable(tf.constant(0.1, shape = [n_days, ]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_model(x_data, w, b):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = rnn_model(x, weights, biases)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(predict, y))\n",
    "optimize = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf,initialize_all_variables())\n",
    "    step = 0\n",
    "    batch_start = 0\n",
    "    batch_end = batch_size\n",
    "    while step * batch_size < train_iters:\n",
    "        batch_start = batch_start//\n",
    "        batch_xs, batch_ys = x_train[batch_start: batch_end], y_train[batch_start: batch_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
